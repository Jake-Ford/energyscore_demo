{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd  # For handling GeoJSON data\n",
    "import folium\n",
    "import branca.colormap as cm\n",
    "from streamlit_folium import folium_static  # Import to render folium maps in Streamlit\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "fico_threshold = 650\n",
    "energy_score_threshold = 0.5\n",
    "\n",
    "solstice_territory_name = \"Central Hudson\"\n",
    "\n",
    "\n",
    "def get_solstice_territory_geojson(solstice_territory_name):\n",
    "    load_name = \"filtered_geojsons/\" + solstice_territory_name + '.geojson'\n",
    "    temp = gpd.read_file(load_name)\n",
    "    temp['Utility'] = solstice_territory_name\n",
    "    return temp\n",
    "\n",
    "zip_geojson = get_solstice_territory_geojson(solstice_territory_name)\n",
    "\n",
    "\n",
    "person_data = pd.read_csv('data.csv', dtype={'ZIP': str})\n",
    "\n",
    "# Ensure ZIP codes have leading zeros and handle floats\n",
    "person_data['ZIP'] = person_data['ZIP'].apply(\n",
    "    lambda x: str(int(float(x))).zfill(5) if pd.notnull(x) else '')\n",
    "\n",
    "# Ensure GeoJSON ZIP codes are formatted as strings with leading zeros\n",
    "zip_geojson['ZIP'] = zip_geojson['ZCTA5CE10'].astype(str).str.zfill(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Massachusetts'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_zip_metrics(stats_data_person, fico_threshold, energy_score_threshold):\n",
    "    stats_data_person['FICO_PASS'] = stats_data_person['FICO_V9_SCORE'] > fico_threshold\n",
    "    stats_data_person['ENERGYSCORE_PASS'] = stats_data_person['WEIGHTED_ENERGYSCORE'] > energy_score_threshold\n",
    "\n",
    "    def calc_metrics(group):\n",
    "        total_population = len(group)\n",
    "        if total_population == 0:\n",
    "            return pd.Series({\n",
    "                'Total Population': 0,\n",
    "                'Percent Below FICO': 0,\n",
    "                'Percent Above FICO': 0,\n",
    "                'FICO Accuracy': np.nan,\n",
    "                'EnergyScore Accuracy': np.nan,\n",
    "                'Qualification Increase': 0,\n",
    "            })\n",
    "\n",
    "        below_fico = group[group['FICO_PASS'] == False]\n",
    "        above_fico = group[group['FICO_PASS'] == True]\n",
    "\n",
    "        below_fico_pass = below_fico[below_fico['WEIGHTED_ENERGYSCORE']\n",
    "                                        <= energy_score_threshold]\n",
    "        pct_below_fico = len(below_fico) / total_population\n",
    "        pct_above_fico = len(above_fico) / total_population\n",
    "\n",
    "        percent_increase_in_qualifications = (\n",
    "            len(below_fico_pass) / total_population) * 100 if len(below_fico_pass) > 0 else 0\n",
    "\n",
    "        fico_accuracy = accuracy_score(\n",
    "            below_fico['WEIGHTED_ACTUAL_OUTPUT'], below_fico['FICO_PASS']) if len(below_fico) > 0 else np.nan\n",
    "        energy_accuracy = accuracy_score(\n",
    "            below_fico['WEIGHTED_ACTUAL_OUTPUT'], below_fico['ENERGYSCORE_PASS']) if len(below_fico) > 0 else np.nan\n",
    "\n",
    "        return pd.Series({\n",
    "            'Total Population': total_population,\n",
    "            'Percent Below FICO': pct_below_fico,\n",
    "            'Percent Above FICO': pct_above_fico,\n",
    "            'FICO Accuracy': fico_accuracy,\n",
    "            'EnergyScore Accuracy': energy_accuracy,\n",
    "            'Qualification Increase': percent_increase_in_qualifications,\n",
    "        })\n",
    "\n",
    "    # Group by ZIP and apply metrics calculation\n",
    "    zip_metrics = stats_data_person.groupby('ZIP').apply(calc_metrics)\n",
    "    zip_metrics = zip_metrics.reset_index()\n",
    "    return zip_metrics\n",
    "\n",
    "\n",
    "def calculate_zip_to_util(zip_level_geo, solstice_territory_name):\n",
    "\n",
    "    # Load the utility data for the region selected\n",
    "    state_util = get_solstice_territory_geojson(solstice_territory_name)\n",
    "\n",
    "\n",
    "    zip_level_geo = pd.merge(zip_metrics, state_util, on='ZIP', how='left')\n",
    "    zip_level_geo = zip_level_geo.dropna(subset=['geometry'])\n",
    "    return zip_level_geo\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "state_name = \"\"\n",
    "calculate_zip_to_util()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZCTA5CE10</th>\n",
       "      <th>GEOID10</th>\n",
       "      <th>CLASSFP10</th>\n",
       "      <th>MTFCC10</th>\n",
       "      <th>FUNCSTAT10</th>\n",
       "      <th>ALAND10</th>\n",
       "      <th>AWATER10</th>\n",
       "      <th>INTPTLAT10</th>\n",
       "      <th>INTPTLON10</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>geometry</th>\n",
       "      <th>Utility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12192</td>\n",
       "      <td>12192</td>\n",
       "      <td>B5</td>\n",
       "      <td>G6350</td>\n",
       "      <td>S</td>\n",
       "      <td>44437302.0</td>\n",
       "      <td>111097.0</td>\n",
       "      <td>+42.4090117</td>\n",
       "      <td>-073.8278389</td>\n",
       "      <td>12192</td>\n",
       "      <td>MULTIPOLYGON (((-73.82379 42.36029, -73.82378 ...</td>\n",
       "      <td>Central Hudson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12193</td>\n",
       "      <td>12193</td>\n",
       "      <td>B5</td>\n",
       "      <td>G6350</td>\n",
       "      <td>S</td>\n",
       "      <td>100695328.0</td>\n",
       "      <td>910351.0</td>\n",
       "      <td>+42.5227595</td>\n",
       "      <td>-074.0432682</td>\n",
       "      <td>12193</td>\n",
       "      <td>MULTIPOLYGON (((-74.11643 42.53985, -74.11592 ...</td>\n",
       "      <td>Central Hudson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12401</td>\n",
       "      <td>12401</td>\n",
       "      <td>B5</td>\n",
       "      <td>G6350</td>\n",
       "      <td>S</td>\n",
       "      <td>151378428.0</td>\n",
       "      <td>3445001.0</td>\n",
       "      <td>+41.9875407</td>\n",
       "      <td>-074.0102727</td>\n",
       "      <td>12401</td>\n",
       "      <td>MULTIPOLYGON (((-74.1925 41.92533, -74.19213 4...</td>\n",
       "      <td>Central Hudson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12404</td>\n",
       "      <td>12404</td>\n",
       "      <td>B5</td>\n",
       "      <td>G6350</td>\n",
       "      <td>S</td>\n",
       "      <td>92428427.0</td>\n",
       "      <td>613979.0</td>\n",
       "      <td>+41.8189583</td>\n",
       "      <td>-074.2360822</td>\n",
       "      <td>12404</td>\n",
       "      <td>MULTIPOLYGON (((-74.29932 41.84775, -74.28781 ...</td>\n",
       "      <td>Central Hudson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12405</td>\n",
       "      <td>12405</td>\n",
       "      <td>B5</td>\n",
       "      <td>G6350</td>\n",
       "      <td>S</td>\n",
       "      <td>18505054.0</td>\n",
       "      <td>75292.0</td>\n",
       "      <td>+42.3179089</td>\n",
       "      <td>-074.0859950</td>\n",
       "      <td>12405</td>\n",
       "      <td>MULTIPOLYGON (((-74.15356 42.33362, -74.15338 ...</td>\n",
       "      <td>Central Hudson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ZCTA5CE10 GEOID10 CLASSFP10 MTFCC10 FUNCSTAT10      ALAND10   AWATER10  \\\n",
       "0     12192   12192        B5   G6350          S   44437302.0   111097.0   \n",
       "1     12193   12193        B5   G6350          S  100695328.0   910351.0   \n",
       "2     12401   12401        B5   G6350          S  151378428.0  3445001.0   \n",
       "3     12404   12404        B5   G6350          S   92428427.0   613979.0   \n",
       "4     12405   12405        B5   G6350          S   18505054.0    75292.0   \n",
       "\n",
       "    INTPTLAT10    INTPTLON10    ZIP  \\\n",
       "0  +42.4090117  -073.8278389  12192   \n",
       "1  +42.5227595  -074.0432682  12193   \n",
       "2  +41.9875407  -074.0102727  12401   \n",
       "3  +41.8189583  -074.2360822  12404   \n",
       "4  +42.3179089  -074.0859950  12405   \n",
       "\n",
       "                                            geometry         Utility  \n",
       "0  MULTIPOLYGON (((-73.82379 42.36029, -73.82378 ...  Central Hudson  \n",
       "1  MULTIPOLYGON (((-74.11643 42.53985, -74.11592 ...  Central Hudson  \n",
       "2  MULTIPOLYGON (((-74.1925 41.92533, -74.19213 4...  Central Hudson  \n",
       "3  MULTIPOLYGON (((-74.29932 41.84775, -74.28781 ...  Central Hudson  \n",
       "4  MULTIPOLYGON (((-74.15356 42.33362, -74.15338 ...  Central Hudson  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_util = get_solstice_territory_geojson(solstice_territory_name)\n",
    "\n",
    "state_util.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4_/36zlcy3x3m12nwb2nfhmkkjc0000gp/T/ipykernel_51815/1390087022.py:43: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  zip_metrics = stats_data_person.groupby('ZIP').apply(calc_metrics)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZIP</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Percent Below FICO</th>\n",
       "      <th>Percent Above FICO</th>\n",
       "      <th>FICO Accuracy</th>\n",
       "      <th>EnergyScore Accuracy</th>\n",
       "      <th>Qualification Increase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01001</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01002</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01005</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01007</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01010</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ZIP  Total Population  Percent Below FICO  Percent Above FICO  \\\n",
       "0  01001              11.0            0.181818            0.818182   \n",
       "1  01002              12.0            0.166667            0.833333   \n",
       "2  01005               3.0            0.000000            1.000000   \n",
       "3  01007              18.0            0.055556            0.944444   \n",
       "4  01010               3.0            0.333333            0.666667   \n",
       "\n",
       "   FICO Accuracy  EnergyScore Accuracy  Qualification Increase  \n",
       "0            1.0                   1.0               18.181818  \n",
       "1            1.0                   1.0               16.666667  \n",
       "2            NaN                   NaN                0.000000  \n",
       "3            1.0                   1.0                5.555556  \n",
       "4            1.0                   1.0               33.333333  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_metrics = calculate_zip_metrics(\n",
    "    person_data, fico_threshold, energy_score_threshold)\n",
    "\n",
    "zip_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZIP</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Percent Below FICO</th>\n",
       "      <th>Percent Above FICO</th>\n",
       "      <th>FICO Accuracy</th>\n",
       "      <th>EnergyScore Accuracy</th>\n",
       "      <th>Qualification Increase</th>\n",
       "      <th>ZCTA5CE10</th>\n",
       "      <th>GEOID10</th>\n",
       "      <th>CLASSFP10</th>\n",
       "      <th>MTFCC10</th>\n",
       "      <th>FUNCSTAT10</th>\n",
       "      <th>ALAND10</th>\n",
       "      <th>AWATER10</th>\n",
       "      <th>INTPTLAT10</th>\n",
       "      <th>INTPTLON10</th>\n",
       "      <th>geometry</th>\n",
       "      <th>Utility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>10512</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10512</td>\n",
       "      <td>10512</td>\n",
       "      <td>B5</td>\n",
       "      <td>G6350</td>\n",
       "      <td>S</td>\n",
       "      <td>141331607.0</td>\n",
       "      <td>14842472.0</td>\n",
       "      <td>+41.4576193</td>\n",
       "      <td>-073.7246077</td>\n",
       "      <td>MULTIPOLYGON (((-73.82153 41.46554, -73.82151 ...</td>\n",
       "      <td>Central Hudson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>10516</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10516</td>\n",
       "      <td>10516</td>\n",
       "      <td>B5</td>\n",
       "      <td>G6350</td>\n",
       "      <td>S</td>\n",
       "      <td>81626886.0</td>\n",
       "      <td>1587119.0</td>\n",
       "      <td>+41.4619726</td>\n",
       "      <td>-073.8749131</td>\n",
       "      <td>MULTIPOLYGON (((-73.97859 41.44212, -73.9783 4...</td>\n",
       "      <td>Central Hudson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>10524</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10524</td>\n",
       "      <td>10524</td>\n",
       "      <td>B5</td>\n",
       "      <td>G6350</td>\n",
       "      <td>S</td>\n",
       "      <td>53839856.0</td>\n",
       "      <td>839861.0</td>\n",
       "      <td>+41.3753251</td>\n",
       "      <td>-073.9262166</td>\n",
       "      <td>MULTIPOLYGON (((-73.9795 41.32216, -73.97924 4...</td>\n",
       "      <td>Central Hudson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>10579</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10579</td>\n",
       "      <td>10579</td>\n",
       "      <td>B5</td>\n",
       "      <td>G6350</td>\n",
       "      <td>S</td>\n",
       "      <td>84788614.0</td>\n",
       "      <td>3613306.0</td>\n",
       "      <td>+41.3953643</td>\n",
       "      <td>-073.8390532</td>\n",
       "      <td>MULTIPOLYGON (((-73.89245 41.34375, -73.89193 ...</td>\n",
       "      <td>Central Hudson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>10916</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10916</td>\n",
       "      <td>10916</td>\n",
       "      <td>B5</td>\n",
       "      <td>G6350</td>\n",
       "      <td>S</td>\n",
       "      <td>52319522.0</td>\n",
       "      <td>234779.0</td>\n",
       "      <td>+41.4423435</td>\n",
       "      <td>-074.2505767</td>\n",
       "      <td>MULTIPOLYGON (((-74.32285 41.43885, -74.32243 ...</td>\n",
       "      <td>Central Hudson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ZIP  Total Population  Percent Below FICO  Percent Above FICO  \\\n",
       "1979  10512               9.0                0.00                1.00   \n",
       "1981  10516               2.0                0.00                1.00   \n",
       "1987  10524               3.0                0.00                1.00   \n",
       "2014  10579               4.0                0.25                0.75   \n",
       "2049  10916               4.0                0.25                0.75   \n",
       "\n",
       "      FICO Accuracy  EnergyScore Accuracy  Qualification Increase ZCTA5CE10  \\\n",
       "1979            NaN                   NaN                     0.0     10512   \n",
       "1981            NaN                   NaN                     0.0     10516   \n",
       "1987            NaN                   NaN                     0.0     10524   \n",
       "2014            1.0                   1.0                    25.0     10579   \n",
       "2049            1.0                   1.0                    25.0     10916   \n",
       "\n",
       "     GEOID10 CLASSFP10 MTFCC10 FUNCSTAT10      ALAND10    AWATER10  \\\n",
       "1979   10512        B5   G6350          S  141331607.0  14842472.0   \n",
       "1981   10516        B5   G6350          S   81626886.0   1587119.0   \n",
       "1987   10524        B5   G6350          S   53839856.0    839861.0   \n",
       "2014   10579        B5   G6350          S   84788614.0   3613306.0   \n",
       "2049   10916        B5   G6350          S   52319522.0    234779.0   \n",
       "\n",
       "       INTPTLAT10    INTPTLON10  \\\n",
       "1979  +41.4576193  -073.7246077   \n",
       "1981  +41.4619726  -073.8749131   \n",
       "1987  +41.3753251  -073.9262166   \n",
       "2014  +41.3953643  -073.8390532   \n",
       "2049  +41.4423435  -074.2505767   \n",
       "\n",
       "                                               geometry         Utility  \n",
       "1979  MULTIPOLYGON (((-73.82153 41.46554, -73.82151 ...  Central Hudson  \n",
       "1981  MULTIPOLYGON (((-73.97859 41.44212, -73.9783 4...  Central Hudson  \n",
       "1987  MULTIPOLYGON (((-73.9795 41.32216, -73.97924 4...  Central Hudson  \n",
       "2014  MULTIPOLYGON (((-73.89245 41.34375, -73.89193 ...  Central Hudson  \n",
       "2049  MULTIPOLYGON (((-74.32285 41.43885, -74.32243 ...  Central Hudson  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_level_geo = pd.merge(zip_metrics, state_util, on='ZIP', how='left')\n",
    "zip_level_geo = zip_level_geo.dropna(subset=['geometry'])\n",
    "zip_level_geo.head()\n",
    "\n",
    "# zip_level_geo = gpd.GeoDataFrame(zip_level_geo, geometry='geometry')\n",
    "\n",
    "# zip_level_geo = zip_level_geo.to_crs(state_util.crs)\n",
    "\n",
    "# zip_level_geo.head()\n",
    "\n",
    "# zip_level_geo.Utility.value_counts()\n",
    "\n",
    "print(zip_level_geo.shape)\n",
    "\n",
    "zip_level_geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4_/36zlcy3x3m12nwb2nfhmkkjc0000gp/T/ipykernel_51815/1390087022.py:43: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  zip_metrics = stats_data_person.groupby('ZIP').apply(calc_metrics)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'index_right' cannot be a column name in the frames being joined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[160], line 16\u001b[0m\n\u001b[1;32m     11\u001b[0m zip_level_geo \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39msjoin(\n\u001b[1;32m     12\u001b[0m     zip_level_geo, state_util, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, predicate\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwithin\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Use the new function to calculate ZIP to utility metrics\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m state_util \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_zip_to_util\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzip_level_geo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolstice_territory_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[158], line 62\u001b[0m, in \u001b[0;36mcalculate_zip_to_util\u001b[0;34m(zip_level_geo, state_name)\u001b[0m\n\u001b[1;32m     59\u001b[0m zip_level_geo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m zip_level_geo\u001b[38;5;241m.\u001b[39mrepresentative_point()\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Perform spatial join with utility data based on point locations\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m zip_level_geo \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msjoin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mzip_level_geo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_util\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwithin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m zip_level_geo\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUtility_right\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUtility\u001b[39m\u001b[38;5;124m'\u001b[39m}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Group by utility name ('new_name') and calculate the mean of 'Qualification Increase'\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/demo_es_st/lib/python3.10/site-packages/geopandas/tools/sjoin.py:120\u001b[0m, in \u001b[0;36msjoin\u001b[0;34m(left_df, right_df, how, predicate, lsuffix, rsuffix, distance, on_attribute, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m _basic_checks(left_df, right_df, how, lsuffix, rsuffix, on_attribute\u001b[38;5;241m=\u001b[39mon_attribute),\n\u001b[1;32m    116\u001b[0m indices \u001b[38;5;241m=\u001b[39m _geom_predicate_query(\n\u001b[1;32m    117\u001b[0m     left_df, right_df, predicate, distance, on_attribute\u001b[38;5;241m=\u001b[39mon_attribute\n\u001b[1;32m    118\u001b[0m )\n\u001b[0;32m--> 120\u001b[0m joined, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_frame_join\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mleft_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlsuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrsuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_attribute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_attribute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m joined\n",
      "File \u001b[0;32m~/miniconda3/envs/demo_es_st/lib/python3.10/site-packages/geopandas/tools/sjoin.py:469\u001b[0m, in \u001b[0;36m_frame_join\u001b[0;34m(left_df, right_df, indices, distances, how, lsuffix, rsuffix, predicate, on_attribute)\u001b[0m\n\u001b[1;32m    467\u001b[0m right_nlevels \u001b[38;5;241m=\u001b[39m right_df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnlevels\n\u001b[1;32m    468\u001b[0m right_index_original \u001b[38;5;241m=\u001b[39m right_df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnames\n\u001b[0;32m--> 469\u001b[0m right_df, right_column_names \u001b[38;5;241m=\u001b[39m \u001b[43m_reset_index_with_suffix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mright_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrsuffix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# if conflicting names in left and right, add suffix\u001b[39;00m\n\u001b[1;32m    472\u001b[0m left_column_names, right_column_names \u001b[38;5;241m=\u001b[39m _process_column_names_with_suffix(\n\u001b[1;32m    473\u001b[0m     left_column_names,\n\u001b[1;32m    474\u001b[0m     right_column_names,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    477\u001b[0m     right_df,\n\u001b[1;32m    478\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/demo_es_st/lib/python3.10/site-packages/geopandas/tools/sjoin.py:288\u001b[0m, in \u001b[0;36m_reset_index_with_suffix\u001b[0;34m(df, suffix, other)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;66;03m# check new label will not be in other dataframe\u001b[39;00m\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_label \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;129;01mor\u001b[39;00m new_label \u001b[38;5;129;01min\u001b[39;00m other\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m--> 288\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m cannot be a column name in the frames being\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    290\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m joined\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(new_label)\n\u001b[1;32m    291\u001b[0m             )\n\u001b[1;32m    292\u001b[0m         column_names[i] \u001b[38;5;241m=\u001b[39m new_label\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df_reset, pd\u001b[38;5;241m.\u001b[39mIndex(column_names)\n",
      "\u001b[0;31mValueError\u001b[0m: 'index_right' cannot be a column name in the frames being joined"
     ]
    }
   ],
   "source": [
    "zip_metrics = calculate_zip_metrics(\n",
    "    person_data, fico_threshold, energy_score_threshold)\n",
    "zip_level_geo = pd.merge(zip_metrics, zip_geojson, on='ZIP', how='left')\n",
    "zip_level_geo = zip_level_geo.dropna(subset=['geometry'])\n",
    "zip_level_geo = gpd.GeoDataFrame(zip_level_geo, geometry='geometry')\n",
    "\n",
    "zip_level_geo = zip_level_geo.to_crs(state_util.crs)\n",
    "\n",
    "zip_level_geo['geometry'] = zip_level_geo.representative_point()\n",
    "\n",
    "zip_level_geo = gpd.sjoin(\n",
    "    zip_level_geo, state_util, how='left', predicate='within')\n",
    "\n",
    "\n",
    "# Use the new function to calculate ZIP to utility metrics\n",
    "state_util = calculate_zip_to_util(zip_level_geo, solstice_territory_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_level_geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test to combine the output files of Equifax and Experian person level data\n",
    "\n",
    "eq_output = pd.read_csv('../energyscore-model/data/standard/equifax_rf_stats_person.csv')\n",
    "eq_output['ZIP'] = eq_output['ZIP'].apply(lambda x: str(int(float(x))).zfill(5) if pd.notnull(x) else '')\n",
    "eq_output.head()\n",
    "\n",
    "print(eq_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_output = pd.read_csv('../energyscore-model/data/standard/experian_rf_stats_person.csv')\n",
    "ex_output['ZIP'] = ex_output['ZIP'].apply(lambda x: str(int(float(x))).zfill(5) if pd.notnull(x) else '')\n",
    "\n",
    "ex_output.head()\n",
    "\n",
    "print(eq_output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_columns = ['PROFILE_ID', 'NUMBER_OF_TRADELINES', 'WEIGHTED_ENERGYSCORE', \n",
    "                    'WEIGHTED_ACTUAL_OUTPUT', 'FICO_V9_SCORE', 'ZIP']\n",
    "\n",
    "\n",
    "eq_output = eq_output[combined_columns]\n",
    "ex_output = ex_output[combined_columns]\n",
    "\n",
    "combined_df = pd.concat([ex_output, eq_output], ignore_index = True)\n",
    "# combined_output = combined_output[combined_columns]\n",
    "# combined_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the GeoJSON file\n",
    "zip_geojson = gpd.read_file('demo_zips.geojson')\n",
    "\n",
    "# Load person data, forcing ZIP to be read as strings\n",
    "person_data = pd.read_csv('data.csv', dtype={'ZIP': str})\n",
    "\n",
    "# Ensure ZIP codes have leading zeros and handle floats\n",
    "person_data['ZIP'] = person_data['ZIP'].apply(lambda x: str(int(float(x))).zfill(5) if pd.notnull(x) else '')\n",
    "\n",
    "# Ensure GeoJSON ZIP codes are formatted as strings with leading zeros\n",
    "zip_geojson['ZIP'] = zip_geojson['ZCTA5CE10'].astype(str).str.zfill(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_score_threshold=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_data[person_data['ZIP']=='01001'].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7/11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate metrics for each ZIP\n",
    "def calculate_zip_metrics(stats_data_person, fico_threshold, energy_score_threshold):\n",
    "    stats_data_person['FICO_PASS'] = stats_data_person['FICO_V9_SCORE'] < fico_threshold\n",
    "    stats_data_person['ENERGYSCORE_PASS'] = stats_data_person['WEIGHTED_ENERGYSCORE'] > energy_score_threshold\n",
    "\n",
    "    def calc_metrics(group):\n",
    "        total_population = len(group)\n",
    "\n",
    "        if total_population == 0:\n",
    "            return pd.Series({\n",
    "                'Total Population': 0,\n",
    "                'Percent Below FICO': 0,\n",
    "                'Percent Above FICO': 0,\n",
    "                'FICO Accuracy': np.nan,\n",
    "                'EnergyScore Accuracy': np.nan,\n",
    "                'Qualification Increase': 0,\n",
    "            })\n",
    "        \n",
    "        above_fico = group[group['FICO_V9_SCORE'] > fico_threshold]\n",
    "        below_fico = group[group['FICO_V9_SCORE'] < fico_threshold]\n",
    "\n",
    "        below_fico_pass = below_fico[below_fico['WEIGHTED_ENERGYSCORE'] <= energy_score_threshold]\n",
    "        \n",
    "        pct_below_fico = len(below_fico) / total_population\n",
    "        pct_above_fico = len(above_fico) / total_population\n",
    "\n",
    "        percent_increase_in_qualifications = (len(below_fico_pass) / total_population) * 100 if len(below_fico_pass) > 0 else 0\n",
    "        numeric_increase_in_qualifications = len(below_fico_pass) if len(below_fico_pass) > 0 else 0\n",
    "\n",
    "        energy_accuracy = accuracy_score(group['WEIGHTED_ACTUAL_OUTPUT'], group['ENERGYSCORE_PASS']) #if len(below_fico) > 0 else np.nan\n",
    "\n",
    "        fico_accuracy = accuracy_score(group['WEIGHTED_ACTUAL_OUTPUT'], group['FICO_PASS']) #if len(below_fico) > 0 else np.nan\n",
    "\n",
    "        return pd.Series({\n",
    "            'Total Population': total_population,\n",
    "            'Percent Below FICO': pct_below_fico,\n",
    "            'Percent Above FICO': pct_above_fico,\n",
    "            'FICO Accuracy': fico_accuracy,\n",
    "            'EnergyScore Accuracy': energy_accuracy,\n",
    "            'Qualification Increase': percent_increase_in_qualifications,\n",
    "            'Numeric Increase': numeric_increase_in_qualifications,\n",
    "        })\n",
    "\n",
    "    # Group by ZIP and apply metrics calculation\n",
    "    zip_metrics = stats_data_person.groupby('ZIP').apply(calc_metrics)\n",
    "    zip_metrics = zip_metrics.reset_index()\n",
    "    return zip_metrics\n",
    "\n",
    "\n",
    "# Function to calculate ZIP to utility mapping and display on the map\n",
    "def calculate_zip_to_util(zip_level_geo, state_name):\n",
    "    # Load the utility data for the state\n",
    "    state_util = load_state_util(state_name)\n",
    "    state_util.rename(columns={'new_name': 'Utility'}, inplace=True)\n",
    "\n",
    "    # Ensure ZIP code geometries have the same projection as the utility data\n",
    "    zip_level_geo = zip_level_geo.to_crs(state_util.crs)\n",
    "\n",
    "    # Convert the ZIP geometries to representative points\n",
    "    zip_level_geo['geometry'] = zip_level_geo.representative_point()\n",
    "\n",
    "    # Perform spatial join with utility data based on point locations\n",
    "    zip_level_geo = gpd.sjoin(zip_level_geo, state_util, how='left', predicate='within')\n",
    "\n",
    "    # Group by utility name ('new_name') and calculate the mean of 'Qualification Increase'\n",
    "    zip_to_util = zip_level_geo.groupby('Utility')['Qualification Increase'].mean().reset_index()\n",
    "\n",
    "    # Merge utility data with the calculated qualification increase\n",
    "    state_util = state_util.merge(zip_to_util, on='Utility', how='left')\n",
    "\n",
    "    return state_util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_name = \"Massachusetts\"\n",
    "fico_threshold = 650\n",
    "energy_score_threshold = .5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_metrics = calculate_zip_metrics(person_data, fico_threshold, energy_score_threshold)\n",
    "zip_level_geo = pd.merge(zip_metrics, zip_geojson, on='ZIP', how='left')\n",
    "zip_level_geo = zip_level_geo.dropna(subset=['geometry'])\n",
    "zip_level_geo = gpd.GeoDataFrame(zip_level_geo, geometry='geometry')\n",
    "\n",
    "print(zip_metrics['EnergyScore Accuracy'].describe())\n",
    "\n",
    "print(zip_metrics['FICO Accuracy'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_metrics['EnergyScore Accuracy'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_metrics['FICO Accuracy'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_level_geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Step 1: Load the GeoJSON file containing all US ZIP codes\n",
    "us_zip_geojson = gpd.read_file('/Users/jakeford/solstice/energyscore-model/us_zips.geojson')  # Adjust the file path as needed\n",
    "us_zip_geojson['ZIP'] = us_zip_geojson['ZCTA5CE10'].astype(str).str.zfill(5)\n",
    "\n",
    "# Step 2: Load the CSV file containing filter conditions for ZIP codes\n",
    "df = pd.read_csv('//Users/jakeford/Downloads/82284_2024_10_16.csv')  # Load your CSV file\n",
    "\n",
    "# Create a directory to save the output GeoJSON files\n",
    "output_dir = 'filtered_geojsons'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_zipcodes(json_string):\n",
    "    try:\n",
    "        # Replace single quotes with double quotes to make it valid JSON\n",
    "        json_string = json_string.replace(\"'\", \"\\\"\")\n",
    "        # Load the string as a dictionary and extract the list\n",
    "        zipcodes_list = json.loads(json_string)['list']\n",
    "        return zipcodes_list\n",
    "    except (json.JSONDecodeError, KeyError) as e:\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "        return []\n",
    "\n",
    "# Apply the function to the 'zipcodes' column\n",
    "df['zipcodes_list'] = df['zipcodes'].apply(extract_zipcodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    # Get the list of zip codes for the current row\n",
    "    zipcodes_list = row['zipcodes_list']  # Assuming this column now contains the Python list of zip codes\n",
    "    \n",
    "    # Filter the GeoJSON data to include only the relevant ZIP codes\n",
    "    filtered_zip_geojson = us_zip_geojson[us_zip_geojson['ZIP'].isin(zipcodes_list)]\n",
    "    \n",
    "    # Use the 'friendly_name' column for the filename\n",
    "    friendly_name = row['friendly_name']\n",
    "    output_filename = os.path.join(output_dir, f\"{friendly_name}.geojson\")\n",
    "    \n",
    "    # Save the filtered GeoJSON file\n",
    "    filtered_zip_geojson.to_file(output_filename, driver='GeoJSON')\n",
    "    \n",
    "    print(f\"Saved filtered GeoJSON for {friendly_name} to {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fico_threshold = 650\n",
    "energy_score_threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_geojson = gpd.read_file('demo_zips.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_level_geo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_level_geo['Total Population'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the GeoJSON file\n",
    "#zip_geojson = gpd.read_file('select_zips.geojson')\n",
    "\n",
    "zip_geojson = gpd.read_file('demo_zips.geojson')\n",
    "\n",
    "# Load person data, forcing ZIP to be read as strings\n",
    "person_data = pd.read_csv('data.csv', dtype={'ZIP': str})\n",
    "\n",
    "# Ensure ZIP codes have leading zeros and handle floats\n",
    "person_data['ZIP'] = person_data['ZIP'].apply(lambda x: str(int(float(x))).zfill(5) if pd.notnull(x) else '')\n",
    "\n",
    "# Ensure GeoJSON ZIP codes are formatted as strings with leading zeros\n",
    "zip_geojson['ZIP'] = zip_geojson['ZCTA5CE10'].astype(str).str.zfill(5)\n",
    "\n",
    "# Check if ZIPs were properly converted\n",
    "print(person_data['ZIP'].head())\n",
    "print(zip_geojson['ZIP'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate metrics for each ZIP\n",
    "def calculate_zip_metrics(stats_data_person, fico_cutoff, energyscore_cutoff):\n",
    "    # Create masks for conditions\n",
    "    stats_data_person['FICO_PASS'] = stats_data_person['FICO_V9_SCORE'] > fico_cutoff\n",
    "    stats_data_person['ENERGYSCORE_PASS'] = stats_data_person['WEIGHTED_ENERGYSCORE'] > energyscore_cutoff\n",
    "\n",
    "    # Function to calculate various metrics\n",
    "    def calc_metrics(group):\n",
    "        total_population = len(group)\n",
    "        if total_population == 0:\n",
    "            return pd.Series({\n",
    "                'Total Population': 0,\n",
    "                'Percent Below FICO': 0,\n",
    "                'Percent Above FICO': 0,\n",
    "                'FICO Accuracy': np.nan,\n",
    "                'EnergyScore Accuracy': np.nan,\n",
    "                'Qualification Increase': 0,\n",
    "            })\n",
    "        \n",
    "        \n",
    "        below_fico = group[group['FICO_PASS'] == False]\n",
    "        above_fico = group[group['FICO_PASS'] == True]\n",
    "\n",
    "        if len(below_fico) == 0:\n",
    "            return pd.Series({\n",
    "                'Total Population': total_population,\n",
    "                'Percent Below FICO': 0,\n",
    "                'Percent Above FICO': len(above_fico) / total_population,\n",
    "                'FICO Accuracy': np.nan,\n",
    "                'EnergyScore Accuracy': np.nan,\n",
    "                'Qualification Increase': 0,\n",
    "            })\n",
    "\n",
    "        below_fico_pass = below_fico[below_fico['WEIGHTED_ENERGYSCORE'] <= energyscore_cutoff]\n",
    "        below_fico_fail = below_fico[below_fico['WEIGHTED_ENERGYSCORE'] > energyscore_cutoff]\n",
    "\n",
    "        pct_below_fico = len(below_fico) / total_population\n",
    "        pct_above_fico = len(above_fico) / total_population\n",
    "\n",
    "        if len(below_fico_pass) == 0:\n",
    "            percent_increase_in_qualifications = 0\n",
    "        else:\n",
    "            percent_increase_in_qualifications = (len(below_fico_pass) / total_population) * 100\n",
    "\n",
    "        # get FICO accuracy, precision, recall, f1 and roc_auc score\n",
    "       # fico_accuracy = accuracy_score(below_fico['WEIGHTED_ACTUAL_OUTPUT'], below_fico['WEIGHTED_ENERGYSCORE'] > energyscore_cutoff) if len(below_fico) > 0 else np.nan\n",
    "        fico_accuracy = accuracy_score(below_fico['WEIGHTED_ACTUAL_OUTPUT'], below_fico['FICO_PASS']) if len(below_fico) > 0 else np.nan\n",
    "\n",
    "        energy_accuracy = accuracy_score(below_fico['WEIGHTED_ACTUAL_OUTPUT'], below_fico['ENERGYSCORE_PASS']) if len(below_fico) > 0 else np.nan\n",
    "\n",
    "      #  accuracy_increase = energy_accuracy - fico_accuracy\n",
    "\n",
    "        return pd.Series({\n",
    "            'Total Population': total_population,\n",
    "            'Percent Below FICO': pct_below_fico,\n",
    "            'Percent Above FICO': pct_above_fico,\n",
    "            'FICO Accuracy': fico_accuracy,\n",
    "            'EnergyScore Accuracy': energy_accuracy,\n",
    "            'Qualification Increase': percent_increase_in_qualifications,\n",
    "          #  'Accuracy Percentage Increase': accuracy_increase,\n",
    "\n",
    "           # 'Accuracy Percentage Increase': (energy_accuracy - fico_accuracy) / fico_accuracy * 100 if fico_accuracy * energy_accuracy> 0 else 0,\n",
    "           \n",
    "\n",
    "        })\n",
    "\n",
    "    # Group by ZIP and apply metrics calculation\n",
    "    zip_metrics = stats_data_person.groupby('ZIP').apply(calc_metrics)\n",
    "\n",
    "    zip_metrics = zip_metrics.reset_index()\n",
    "    return zip_metrics\n",
    "\n",
    "fico_threshold = 700\n",
    "energy_score_threshold = 0.5\n",
    "# Calculate metrics and merge with geo data\n",
    "zip_metrics = calculate_zip_metrics(person_data, fico_threshold, energy_score_threshold)\n",
    "zip_level_geo = pd.merge(zip_metrics, zip_geojson, on='ZIP', how='left')\n",
    "zip_level_geo = zip_level_geo.dropna(subset=['geometry'])\n",
    "zip_level_geo = gpd.GeoDataFrame(zip_level_geo, geometry='geometry')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_level_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_state_util(state_name):\n",
    "    if state_name == 'New Mexico':\n",
    "        temp = gpd.read_file('nm_utils.geojson')\n",
    "        temp = temp[['new_name', 'geometry']]\n",
    "        return temp\n",
    "    elif state_name == 'Massachusetts':\n",
    "        return gpd.read_file('ma_utils.geojson')\n",
    "\n",
    "\n",
    "def calculate_zip_to_util(zip_level_geo, util_name, state_name):\n",
    "    # Load the utility data for the state\n",
    "    state_util = load_state_util(state_name)\n",
    "\n",
    "    # Ensure ZIP code geometries have the same projection as the utility data\n",
    "    zip_level_geo = zip_level_geo.to_crs(state_util.crs)\n",
    "\n",
    "    # Convert the ZIP geometries to representative points (instead of centroids)\n",
    "    zip_level_geo['geometry'] = zip_level_geo.representative_point()\n",
    "\n",
    "    # Perform spatial join with utility data based on point locations using predicate\n",
    "    zip_level_geo = gpd.sjoin(zip_level_geo, state_util, how='left', predicate='within')\n",
    "\n",
    "    # Group by utility name ('new_name') and calculate the mean of 'Qualification Increase'\n",
    "    zip_to_util = zip_level_geo.groupby('new_name')['Qualification Increase'].mean().reset_index()\n",
    "\n",
    "    return zip_to_util\n",
    "\n",
    "# Example usage\n",
    "state_name = 'New Mexico'\n",
    "util_name = 'Xcel'\n",
    "zip_to_util = calculate_zip_to_util(zip_level_geo, util_name, state_name)\n",
    "zip_to_util.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_level_geo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_metrics['FICO Accuracy'].mean(),zip_metrics['EnergyScore Accuracy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_geojson.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo_es_st",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
